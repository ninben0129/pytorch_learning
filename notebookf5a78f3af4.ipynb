{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-18T10:59:58.003073Z",
     "iopub.status.busy": "2023-06-18T10:59:58.00263Z",
     "iopub.status.idle": "2023-06-18T11:00:14.902032Z",
     "shell.execute_reply": "2023-06-18T11:00:14.900671Z",
     "shell.execute_reply.started": "2023-06-18T10:59:58.003045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install diffusers[\"torch\"] transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:42:09.148596Z",
     "iopub.status.busy": "2023-06-18T06:42:09.148217Z",
     "iopub.status.idle": "2023-06-18T06:42:23.595508Z",
     "shell.execute_reply": "2023-06-18T06:42:23.594524Z",
     "shell.execute_reply.started": "2023-06-18T06:42:09.148565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Load the model and schedulers\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "checkpoint=\"google/ddpm-cat-256\"\n",
    "scheduler = DDPMScheduler.from_pretrained(checkpoint)\n",
    "model = UNet2DModel.from_pretrained(checkpoint).to(\"cuda\")\n",
    "\n",
    "#set the number of timesteps to run the denoising process for\n",
    "scheduler.set_timesteps(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:42:47.159351Z",
     "iopub.status.busy": "2023-06-18T06:42:47.158992Z",
     "iopub.status.idle": "2023-06-18T06:42:47.171931Z",
     "shell.execute_reply": "2023-06-18T06:42:47.17073Z",
     "shell.execute_reply.started": "2023-06-18T06:42:47.159322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scheduler.timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:43:36.691678Z",
     "iopub.status.busy": "2023-06-18T06:43:36.691144Z",
     "iopub.status.idle": "2023-06-18T06:43:36.70074Z",
     "shell.execute_reply": "2023-06-18T06:43:36.699544Z",
     "shell.execute_reply.started": "2023-06-18T06:43:36.691633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:52:28.599367Z",
     "iopub.status.busy": "2023-06-18T06:52:28.598761Z",
     "iopub.status.idle": "2023-06-18T06:52:28.61333Z",
     "shell.execute_reply": "2023-06-18T06:52:28.612256Z",
     "shell.execute_reply.started": "2023-06-18T06:52:28.599324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#create random noise\n",
    "import torch\n",
    "sample_size = model.config.sample_size\n",
    "noise = torch.randn((1, 3, sample_size, sample_size)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:52:32.976477Z",
     "iopub.status.busy": "2023-06-18T06:52:32.976117Z",
     "iopub.status.idle": "2023-06-18T06:52:32.98288Z",
     "shell.execute_reply": "2023-06-18T06:52:32.981556Z",
     "shell.execute_reply.started": "2023-06-18T06:52:32.976446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:52:16.352832Z",
     "iopub.status.busy": "2023-06-18T06:52:16.352414Z",
     "iopub.status.idle": "2023-06-18T06:52:16.358265Z",
     "shell.execute_reply": "2023-06-18T06:52:16.357198Z",
     "shell.execute_reply.started": "2023-06-18T06:52:16.352799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#noise.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a loop: model gives out noise residual, noise residual fed into scheduler. scheduler.step() gives out denoised previous image\n",
    "which is put into the loop again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:52:38.803334Z",
     "iopub.status.busy": "2023-06-18T06:52:38.802971Z",
     "iopub.status.idle": "2023-06-18T06:52:54.0386Z",
     "shell.execute_reply": "2023-06-18T06:52:54.037526Z",
     "shell.execute_reply.started": "2023-06-18T06:52:38.803304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input = noise\n",
    "\n",
    "for t in scheduler.timesteps:\n",
    "    #noise residual\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    #denoise\n",
    "    previous_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=t, sample=input).prev_sample\n",
    "    \n",
    "    input = previous_noisy_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:54:05.279417Z",
     "iopub.status.busy": "2023-06-18T06:54:05.27905Z",
     "iopub.status.idle": "2023-06-18T06:54:05.327037Z",
     "shell.execute_reply": "2023-06-18T06:54:05.326141Z",
     "shell.execute_reply.started": "2023-06-18T06:54:05.279386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = (input / 2 + 0.5).clamp(0, 1)\n",
    "image = image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "image = Image.fromarray((image * 255).round().astype(\"uint8\"))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconstruct stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T06:57:39.744339Z",
     "iopub.status.busy": "2023-06-18T06:57:39.743931Z",
     "iopub.status.idle": "2023-06-18T06:57:39.750311Z",
     "shell.execute_reply": "2023-06-18T06:57:39.7491Z",
     "shell.execute_reply.started": "2023-06-18T06:57:39.744306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\n",
    "\n",
    "checkpoint = \"CompVis/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:00:48.565975Z",
     "iopub.status.busy": "2023-06-18T07:00:48.565589Z",
     "iopub.status.idle": "2023-06-18T07:01:44.872425Z",
     "shell.execute_reply": "2023-06-18T07:01:44.871451Z",
     "shell.execute_reply.started": "2023-06-18T07:00:48.565938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(checkpoint, subfolder=\"vae\")\n",
    "model = UNet2DConditionModel.from_pretrained(checkpoint, subfolder=\"unet\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(checkpoint, subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(checkpoint, subfolder=\"text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:02:56.923402Z",
     "iopub.status.busy": "2023-06-18T07:02:56.922407Z",
     "iopub.status.idle": "2023-06-18T07:02:57.139659Z",
     "shell.execute_reply": "2023-06-18T07:02:57.138764Z",
     "shell.execute_reply.started": "2023-06-18T07:02:56.923368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from diffusers import UniPCMultistepScheduler\n",
    "shecduler = UniPCMultistepScheduler.from_pretrained(checkpoint, subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:04:06.922054Z",
     "iopub.status.busy": "2023-06-18T07:04:06.921335Z",
     "iopub.status.idle": "2023-06-18T07:04:18.031726Z",
     "shell.execute_reply": "2023-06-18T07:04:18.030788Z",
     "shell.execute_reply.started": "2023-06-18T07:04:06.922011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "vae.to(device)\n",
    "text_encoder.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:07:33.705688Z",
     "iopub.status.busy": "2023-06-18T07:07:33.705314Z",
     "iopub.status.idle": "2023-06-18T07:07:33.710969Z",
     "shell.execute_reply": "2023-06-18T07:07:33.709994Z",
     "shell.execute_reply.started": "2023-06-18T07:07:33.705654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = [\"a cat is playing football wearing the Argentina jersey of Messi\"]\n",
    "height = 512\n",
    "width = 512\n",
    "num_inference_steps = 25\n",
    "guidance_scale = 7.5\n",
    "generator = torch.manual_seed(0)\n",
    "batch_size = len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:12:53.412853Z",
     "iopub.status.busy": "2023-06-18T07:12:53.412431Z",
     "iopub.status.idle": "2023-06-18T07:12:53.567432Z",
     "shell.execute_reply": "2023-06-18T07:12:53.566438Z",
     "shell.execute_reply.started": "2023-06-18T07:12:53.412822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:14:55.784093Z",
     "iopub.status.busy": "2023-06-18T07:14:55.783708Z",
     "iopub.status.idle": "2023-06-18T07:14:55.827327Z",
     "shell.execute_reply": "2023-06-18T07:14:55.826387Z",
     "shell.execute_reply.started": "2023-06-18T07:14:55.784061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:15:45.561381Z",
     "iopub.status.busy": "2023-06-18T07:15:45.560213Z",
     "iopub.status.idle": "2023-06-18T07:15:45.567841Z",
     "shell.execute_reply": "2023-06-18T07:15:45.566719Z",
     "shell.execute_reply.started": "2023-06-18T07:15:45.561339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:19:05.652149Z",
     "iopub.status.busy": "2023-06-18T07:19:05.651669Z",
     "iopub.status.idle": "2023-06-18T07:19:05.660589Z",
     "shell.execute_reply": "2023-06-18T07:19:05.659614Z",
     "shell.execute_reply.started": "2023-06-18T07:19:05.652106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:19:59.685537Z",
     "iopub.status.busy": "2023-06-18T07:19:59.685137Z",
     "iopub.status.idle": "2023-06-18T07:19:59.691799Z",
     "shell.execute_reply": "2023-06-18T07:19:59.690482Z",
     "shell.execute_reply.started": "2023-06-18T07:19:59.685479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:23:01.720465Z",
     "iopub.status.busy": "2023-06-18T07:23:01.719396Z",
     "iopub.status.idle": "2023-06-18T07:23:01.72677Z",
     "shell.execute_reply": "2023-06-18T07:23:01.725858Z",
     "shell.execute_reply.started": "2023-06-18T07:23:01.720403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#why divided by 8:  vae model has 3 down-sampling layers.\n",
    "2 ** (len(vae.config.block_out_channels) - 1) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:21:32.708993Z",
     "iopub.status.busy": "2023-06-18T07:21:32.708434Z",
     "iopub.status.idle": "2023-06-18T07:21:32.737769Z",
     "shell.execute_reply": "2023-06-18T07:21:32.73682Z",
     "shell.execute_reply.started": "2023-06-18T07:21:32.708951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latents = torch.randn((batch_size, model.config.in_channels, height//8, width//8), generator=generator)\n",
    "latents.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:26:19.568905Z",
     "iopub.status.busy": "2023-06-18T07:26:19.568525Z",
     "iopub.status.idle": "2023-06-18T07:26:19.57589Z",
     "shell.execute_reply": "2023-06-18T07:26:19.574942Z",
     "shell.execute_reply.started": "2023-06-18T07:26:19.568876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:26:24.122593Z",
     "iopub.status.busy": "2023-06-18T07:26:24.122195Z",
     "iopub.status.idle": "2023-06-18T07:26:24.128417Z",
     "shell.execute_reply": "2023-06-18T07:26:24.127531Z",
     "shell.execute_reply.started": "2023-06-18T07:26:24.12256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#scaling the input with the initial noise distribution, sigma\n",
    "latents = latents * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:33:49.931032Z",
     "iopub.status.busy": "2023-06-18T07:33:49.930597Z",
     "iopub.status.idle": "2023-06-18T07:33:49.947808Z",
     "shell.execute_reply": "2023-06-18T07:33:49.946851Z",
     "shell.execute_reply.started": "2023-06-18T07:33:49.930992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latents.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:36:38.844652Z",
     "iopub.status.busy": "2023-06-18T07:36:38.844235Z",
     "iopub.status.idle": "2023-06-18T07:36:38.857119Z",
     "shell.execute_reply": "2023-06-18T07:36:38.85601Z",
     "shell.execute_reply.started": "2023-06-18T07:36:38.844607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:38:52.412638Z",
     "iopub.status.busy": "2023-06-18T07:38:52.412199Z",
     "iopub.status.idle": "2023-06-18T07:38:52.443073Z",
     "shell.execute_reply": "2023-06-18T07:38:52.442123Z",
     "shell.execute_reply.started": "2023-06-18T07:38:52.412605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:40:40.057048Z",
     "iopub.status.busy": "2023-06-18T07:40:40.056573Z",
     "iopub.status.idle": "2023-06-18T07:40:40.068478Z",
     "shell.execute_reply": "2023-06-18T07:40:40.06756Z",
     "shell.execute_reply.started": "2023-06-18T07:40:40.057002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:43:07.330928Z",
     "iopub.status.busy": "2023-06-18T07:43:07.330472Z",
     "iopub.status.idle": "2023-06-18T07:43:18.801164Z",
     "shell.execute_reply": "2023-06-18T07:43:18.799899Z",
     "shell.execute_reply.started": "2023-06-18T07:43:07.330896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "for t in tqdm(scheduler.timesteps):\n",
    "    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
    "    latent_model_input = torch.cat([latents]*2)\n",
    "    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise_pred = model(latent_model_input.cuda(), t, encoder_hidden_states=text_embeddings).sample\n",
    "    \n",
    "    \n",
    "    #perform guidance\n",
    "    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "    \n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    # compute the previous noisy sample x_t -> x_t-1\n",
    "\n",
    "    latents = scheduler.step(noise_pred.cuda(), t, latents.cuda()).prev_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:43:57.995549Z",
     "iopub.status.busy": "2023-06-18T07:43:57.995069Z",
     "iopub.status.idle": "2023-06-18T07:43:58.021072Z",
     "shell.execute_reply": "2023-06-18T07:43:58.019924Z",
     "shell.execute_reply.started": "2023-06-18T07:43:57.995473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# scale and decode the image latents with vae\n",
    "latents = 1 / 0.18215 * latents\n",
    "with torch.no_grad():\n",
    "    image = vae.decode(latents).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T07:44:05.384973Z",
     "iopub.status.busy": "2023-06-18T07:44:05.384138Z",
     "iopub.status.idle": "2023-06-18T07:44:05.508636Z",
     "shell.execute_reply": "2023-06-18T07:44:05.507573Z",
     "shell.execute_reply.started": "2023-06-18T07:44:05.384939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "\n",
    "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "images = (image * 255).round().astype(\"uint8\")\n",
    "\n",
    "pil_images = [Image.fromarray(image) for image in images]\n",
    "\n",
    "pil_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:03:32.047666Z",
     "iopub.status.busy": "2023-06-18T11:03:32.046844Z",
     "iopub.status.idle": "2023-06-18T11:03:34.084472Z",
     "shell.execute_reply": "2023-06-18T11:03:34.083184Z",
     "shell.execute_reply.started": "2023-06-18T11:03:32.04763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:10:52.040413Z",
     "iopub.status.busy": "2023-06-18T11:10:52.039725Z",
     "iopub.status.idle": "2023-06-18T11:10:52.04702Z",
     "shell.execute_reply": "2023-06-18T11:10:52.045792Z",
     "shell.execute_reply.started": "2023-06-18T11:10:52.040382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 128  # the generated image resolution\n",
    "    train_batch_size = 16\n",
    "    eval_batch_size = 16  # how many images to sample during evaluation\n",
    "    num_epochs = 50\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 10\n",
    "    save_model_epochs = 30\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"ddpm-butterflies-128\"  # the model name locally and on the HF Hub\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    hub_private_repo = False\n",
    "    overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:10:53.904517Z",
     "iopub.status.busy": "2023-06-18T11:10:53.903811Z",
     "iopub.status.idle": "2023-06-18T11:10:53.910886Z",
     "shell.execute_reply": "2023-06-18T11:10:53.908103Z",
     "shell.execute_reply.started": "2023-06-18T11:10:53.904487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:21:47.312355Z",
     "iopub.status.busy": "2023-06-18T11:21:47.31198Z",
     "iopub.status.idle": "2023-06-18T11:21:47.854736Z",
     "shell.execute_reply": "2023-06-18T11:21:47.853863Z",
     "shell.execute_reply.started": "2023-06-18T11:21:47.312325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "config.dataset_name = \"huggan/few-shot-obama\"\n",
    "dataset = load_dataset(config.dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:22:38.984622Z",
     "iopub.status.busy": "2023-06-18T11:22:38.984162Z",
     "iopub.status.idle": "2023-06-18T11:22:39.605366Z",
     "shell.execute_reply": "2023-06-18T11:22:39.604495Z",
     "shell.execute_reply.started": "2023-06-18T11:22:38.984582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, image in enumerate(dataset[:4][\"image\"]):\n",
    "    print(image.size)\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:22:59.872017Z",
     "iopub.status.busy": "2023-06-18T11:22:59.871639Z",
     "iopub.status.idle": "2023-06-18T11:22:59.87752Z",
     "shell.execute_reply": "2023-06-18T11:22:59.876422Z",
     "shell.execute_reply.started": "2023-06-18T11:22:59.871986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:23:24.035721Z",
     "iopub.status.busy": "2023-06-18T11:23:24.035328Z",
     "iopub.status.idle": "2023-06-18T11:23:24.041686Z",
     "shell.execute_reply": "2023-06-18T11:23:24.040686Z",
     "shell.execute_reply.started": "2023-06-18T11:23:24.035689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform(examples):\n",
    "    images = [preprocess(image.convert(\"RGB\"))  for image in examples[\"image\"]]\n",
    "    return {\"images\":images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:23:31.586627Z",
     "iopub.status.busy": "2023-06-18T11:23:31.586278Z",
     "iopub.status.idle": "2023-06-18T11:23:31.593984Z",
     "shell.execute_reply": "2023-06-18T11:23:31.592858Z",
     "shell.execute_reply.started": "2023-06-18T11:23:31.586598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:23:37.675634Z",
     "iopub.status.busy": "2023-06-18T11:23:37.675269Z",
     "iopub.status.idle": "2023-06-18T11:23:37.681671Z",
     "shell.execute_reply": "2023-06-18T11:23:37.680738Z",
     "shell.execute_reply.started": "2023-06-18T11:23:37.675604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:25:25.758187Z",
     "iopub.status.busy": "2023-06-18T11:25:25.75761Z",
     "iopub.status.idle": "2023-06-18T11:25:25.783051Z",
     "shell.execute_reply": "2023-06-18T11:25:25.781899Z",
     "shell.execute_reply.started": "2023-06-18T11:25:25.758153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset[:1][\"images\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:27:06.153786Z",
     "iopub.status.busy": "2023-06-18T11:27:06.153404Z",
     "iopub.status.idle": "2023-06-18T11:27:06.159077Z",
     "shell.execute_reply": "2023-06-18T11:27:06.157979Z",
     "shell.execute_reply.started": "2023-06-18T11:27:06.153755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UNet2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:32:29.432924Z",
     "iopub.status.busy": "2023-06-18T11:32:29.432539Z",
     "iopub.status.idle": "2023-06-18T11:32:49.95809Z",
     "shell.execute_reply": "2023-06-18T11:32:49.957094Z",
     "shell.execute_reply.started": "2023-06-18T11:32:29.432893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.image_size,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "        down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:33:19.551447Z",
     "iopub.status.busy": "2023-06-18T11:33:19.550637Z",
     "iopub.status.idle": "2023-06-18T11:33:31.014711Z",
     "shell.execute_reply": "2023-06-18T11:33:31.013135Z",
     "shell.execute_reply.started": "2023-06-18T11:33:19.551403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:33:55.484065Z",
     "iopub.status.busy": "2023-06-18T11:33:55.483528Z",
     "iopub.status.idle": "2023-06-18T11:33:55.494281Z",
     "shell.execute_reply": "2023-06-18T11:33:55.493257Z",
     "shell.execute_reply.started": "2023-06-18T11:33:55.484021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset[0][\"images\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:34:23.664845Z",
     "iopub.status.busy": "2023-06-18T11:34:23.664473Z",
     "iopub.status.idle": "2023-06-18T11:34:23.676007Z",
     "shell.execute_reply": "2023-06-18T11:34:23.674853Z",
     "shell.execute_reply.started": "2023-06-18T11:34:23.664796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset[0][\"images\"].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:36:04.599423Z",
     "iopub.status.busy": "2023-06-18T11:36:04.599077Z",
     "iopub.status.idle": "2023-06-18T11:36:04.610505Z",
     "shell.execute_reply": "2023-06-18T11:36:04.609549Z",
     "shell.execute_reply.started": "2023-06-18T11:36:04.599392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:38:11.170677Z",
     "iopub.status.busy": "2023-06-18T11:38:11.170202Z",
     "iopub.status.idle": "2023-06-18T11:38:11.1863Z",
     "shell.execute_reply": "2023-06-18T11:38:11.185257Z",
     "shell.execute_reply.started": "2023-06-18T11:38:11.170636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_image = dataset[0][\"images\"]\n",
    "sample_image = einops.rearrange(sample_image, \"c h w -> 1 c h w\")\n",
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:39:00.825571Z",
     "iopub.status.busy": "2023-06-18T11:39:00.824484Z",
     "iopub.status.idle": "2023-06-18T11:39:03.896647Z",
     "shell.execute_reply": "2023-06-18T11:39:03.8958Z",
     "shell.execute_reply.started": "2023-06-18T11:39:00.825526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model(sample_image, timestep=0).sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:46:05.129595Z",
     "iopub.status.busy": "2023-06-18T11:46:05.129247Z",
     "iopub.status.idle": "2023-06-18T11:46:05.137741Z",
     "shell.execute_reply": "2023-06-18T11:46:05.136749Z",
     "shell.execute_reply.started": "2023-06-18T11:46:05.129565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "noise = torch.randn(sample_image.shape)\n",
    "timesteps = torch.LongTensor([50])\n",
    "noisy_image = noise_scheduler.add_noise(original_samples=sample_image, noise=noise, timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:46:20.845592Z",
     "iopub.status.busy": "2023-06-18T11:46:20.845086Z",
     "iopub.status.idle": "2023-06-18T11:46:20.858127Z",
     "shell.execute_reply": "2023-06-18T11:46:20.856927Z",
     "shell.execute_reply.started": "2023-06-18T11:46:20.845547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noisy_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:48:25.525385Z",
     "iopub.status.busy": "2023-06-18T11:48:25.524696Z",
     "iopub.status.idle": "2023-06-18T11:48:25.539666Z",
     "shell.execute_reply": "2023-06-18T11:48:25.538455Z",
     "shell.execute_reply.started": "2023-06-18T11:48:25.525343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#move the channel to the last dim for PIL\n",
    "x = einops.rearrange(noisy_image, \"b c h w -> b h w c\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:48:44.627071Z",
     "iopub.status.busy": "2023-06-18T11:48:44.626671Z",
     "iopub.status.idle": "2023-06-18T11:48:44.642457Z",
     "shell.execute_reply": "2023-06-18T11:48:44.640682Z",
     "shell.execute_reply.started": "2023-06-18T11:48:44.627039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(((x + 1.0) * 127.5).type(torch.uint8).numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of training is to predict the noise added to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:51:25.865428Z",
     "iopub.status.busy": "2023-06-18T11:51:25.864801Z",
     "iopub.status.idle": "2023-06-18T11:51:27.439187Z",
     "shell.execute_reply": "2023-06-18T11:51:27.438208Z",
     "shell.execute_reply.started": "2023-06-18T11:51:25.86537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "noise_pred = model(noisy_image, timesteps).sample\n",
    "loss = F.mse_loss(noise_pred, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T11:58:47.105138Z",
     "iopub.status.busy": "2023-06-18T11:58:47.104601Z",
     "iopub.status.idle": "2023-06-18T11:58:47.131591Z",
     "shell.execute_reply": "2023-06-18T11:58:47.130665Z",
     "shell.execute_reply.started": "2023-06-18T11:58:47.105097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(len(train_dataloader) * config.num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:02:39.895242Z",
     "iopub.status.busy": "2023-06-18T12:02:39.894816Z",
     "iopub.status.idle": "2023-06-18T12:02:39.90166Z",
     "shell.execute_reply": "2023-06-18T12:02:39.900744Z",
     "shell.execute_reply.started": "2023-06-18T12:02:39.895209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "import math\n",
    "import os\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:04:52.995318Z",
     "iopub.status.busy": "2023-06-18T12:04:52.99486Z",
     "iopub.status.idle": "2023-06-18T12:04:53.003132Z",
     "shell.execute_reply": "2023-06-18T12:04:53.001902Z",
     "shell.execute_reply.started": "2023-06-18T12:04:52.995283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(config, epoch, pipeline):\n",
    "    images = pipeline(batch_size=config.eval_batch_size,generator=torch.manual_seed(config.seed),).images\n",
    "    \n",
    "    # Make a grid out of the images\n",
    "    image_grid = make_grid(images, rows=4, cols=4)\n",
    "\n",
    "    # Save the images\n",
    "    test_dir = os.path.join(config.output_dir, \"samples\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(f\"{test_dir}/{epoch:04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:38:01.750848Z",
     "iopub.status.busy": "2023-06-18T12:38:01.750458Z",
     "iopub.status.idle": "2023-06-18T12:38:13.988991Z",
     "shell.execute_reply": "2023-06-18T12:38:13.987559Z",
     "shell.execute_reply.started": "2023-06-18T12:38:01.750799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:38:29.639899Z",
     "iopub.status.busy": "2023-06-18T12:38:29.638769Z",
     "iopub.status.idle": "2023-06-18T12:38:40.606675Z",
     "shell.execute_reply": "2023-06-18T12:38:40.605344Z",
     "shell.execute_reply.started": "2023-06-18T12:38:29.639848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip show accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:41:57.075112Z",
     "iopub.status.busy": "2023-06-18T12:41:57.074318Z",
     "iopub.status.idle": "2023-06-18T12:41:58.235577Z",
     "shell.execute_reply": "2023-06-18T12:41:58.234173Z",
     "shell.execute_reply.started": "2023-06-18T12:41:57.075062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:38:50.203049Z",
     "iopub.status.busy": "2023-06-18T12:38:50.202631Z",
     "iopub.status.idle": "2023-06-18T12:38:50.221754Z",
     "shell.execute_reply": "2023-06-18T12:38:50.220755Z",
     "shell.execute_reply.started": "2023-06-18T12:38:50.20301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision = config.mixed_precision,\n",
    "        gradient_accumulation_steps = config.gradient_accumulation_steps,\n",
    "        log_with=\"tensorboard\",\n",
    "        logging_dir=os.path.join(config.output_dir, \"logs\"),\n",
    "    )\n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        if config.output_dir is not None:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "        accelerator.init_trackers(\"train_example\")\n",
    "        \n",
    "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, lr_scheduler\n",
    "    )\n",
    "    \n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            clean_images = batch[\"images\"]\n",
    "            noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
    "            batch_size = clean_images.shape[0]\n",
    "            \n",
    "            #sample random timestep for each image\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (batch_size,), device=clean_images.device).long()\n",
    "        \n",
    "            #add noise to each clean image for each random timestep\n",
    "            #this is the forward diffusion process\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "            \n",
    "            with accelerator.accumulate(model):\n",
    "                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "                loss = F.mse_loss(noise_pred, noise)\n",
    "                accelerator.backward(loss)\n",
    "                \n",
    "                accelerator.clip_grad_norm_(model.parameters(),1.0)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            accelerator.log(logs, step=global_step)\n",
    "            global_step += 1\n",
    "            \n",
    "       # After each epoch you optionally sample some demo images with evaluate() and save the model\n",
    "        if accelerator.is_main_process:\n",
    "            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "            if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                evaluate(config, epoch, pipeline)\n",
    "            if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                    pipeline.save_pretrained(config.output_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T12:38:55.353894Z",
     "iopub.status.busy": "2023-06-18T12:38:55.353401Z",
     "iopub.status.idle": "2023-06-18T12:39:00.594358Z",
     "shell.execute_reply": "2023-06-18T12:39:00.59284Z",
     "shell.execute_reply.started": "2023-06-18T12:38:55.353815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher\n",
    "args = (config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)\n",
    "notebook_launcher(train_loop, args, num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 30657,
     "sourceId": 44655,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30513,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
